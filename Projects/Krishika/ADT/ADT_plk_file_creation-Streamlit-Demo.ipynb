{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1350913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly.graph_objects as go\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701a54db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Factor: 182.5204961109943\n",
      "% increase: 0.4239338541321323\n",
      "% increase: 0.3074988430156789\n",
      "% increase: 0.3708261589685712\n",
      "% increase: 0.4976813389239167\n",
      "% increase: 0.3975210925249858\n",
      "% increase: 0.4219594918201598\n",
      "Year\n",
      "2015    48878\n",
      "2016    47117\n",
      "2017    51754\n",
      "2018    59118\n",
      "2019    57559\n",
      "2020    61011\n",
      "Name: Patient ID, dtype: int64\n",
      "Year\n",
      "2015          NaN\n",
      "2016    -3.602848\n",
      "2017     9.841458\n",
      "2018    14.228852\n",
      "2019    -2.637099\n",
      "2020     5.997324\n",
      "Name: Patient ID, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the mode_of_arrival options\n",
    "mode_of_arrival_options = ['Ambulance', 'Own Vehicle', 'Walk In', 'Other']\n",
    "\n",
    "# Define the disposition options\n",
    "disposition_options = ['HOME', 'ADMITTED', 'ELOPED', 'LEFT WITHOUT BEING SEEN', 'OTHER', 'LEFT AGAINST MEDICAL ADVICE', 'EXPIRED']\n",
    "\n",
    "# Define the gender options\n",
    "gender_options = ['M', 'F']\n",
    "\n",
    "# Set a seed for reproducibility (optional)\n",
    "random.seed(2020)\n",
    "\n",
    "desired_total_count = 34730\n",
    "\n",
    "# List of values specifying the number of IDs to generate for each month\n",
    "original_num_ids_list = [15.42, 15.23, 15.30, 15.82, 15.77, 15.98, 15.72, 16.18, 16.27, 16.24, 16.07, 16.28]\n",
    "\n",
    "# Calculate the total number of IDs generated in a year\n",
    "total_ids_in_year = sum(original_num_ids_list)\n",
    "\n",
    "# Define the scaling factor\n",
    "scaling_factor = desired_total_count / total_ids_in_year\n",
    "\n",
    "print('Scaling Factor:', scaling_factor)\n",
    "\n",
    "# Calculate the scaled number of IDs for each month\n",
    "num_ids_list = [int(original_num_ids * scaling_factor) for original_num_ids in original_num_ids_list]\n",
    "\n",
    "# Define the start and end years, including a leap year\n",
    "start_year = 2015\n",
    "end_year = 2020\n",
    "\n",
    "# Create an empty list to store data\n",
    "data = []\n",
    "\n",
    "# Initialize a linear trend factor\n",
    "linear_trend_factor = 1\n",
    "\n",
    "# Loop through each year\n",
    "for year in range(start_year, end_year + 1):\n",
    "    # Introduce a random percentage increase between 20% and 50%\n",
    "    percentage_increase = random.uniform(0.30, 0.50)\n",
    "    print('% increase:', percentage_increase)\n",
    "    num_ids_list_with_increase = [int(num_ids * (1 + percentage_increase)) for num_ids in num_ids_list]\n",
    "\n",
    "    # Apply the linear trend factor\n",
    "    num_ids_list_with_trend = [int(num_ids * linear_trend_factor) for num_ids in num_ids_list_with_increase]\n",
    "\n",
    "    # Adjust the linear trend factor for the next year (you can customize this)\n",
    "    linear_trend_factor += 0.05  # Adjust the trend factor as needed\n",
    "\n",
    "    # Determine if the current year is a leap year\n",
    "    is_leap_year = (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n",
    "\n",
    "    # Calculate the number of patients with 'Transfer_date' for the current year\n",
    "    total_admissions = sum(num_ids_list_with_trend)\n",
    "    num_transfer_patients = int(total_admissions * 0.035)\n",
    "\n",
    "    # Calculate the number of transfer patients for the current year\n",
    "    num_transfer_patients_yearly = int(total_admissions * 0.035)\n",
    "\n",
    "    # Spread out transfer patients throughout the year\n",
    "    transfer_month_distribution = [int(num_transfer_patients_yearly / 12)] * 12\n",
    "    remaining_transfers = num_transfer_patients_yearly % 12\n",
    "\n",
    "    # Distribute the remaining transfer patients randomly across the months\n",
    "    for _ in range(remaining_transfers):\n",
    "        random_month = random.randint(0, 11)\n",
    "        transfer_month_distribution[random_month] += 1\n",
    "\n",
    "    # Loop through each month\n",
    "    for month, num_ids in enumerate(num_ids_list_with_trend, start=1):\n",
    "        # Introduce seasonality by varying the number of IDs based on the month\n",
    "        seasonality_factor = 1 + np.sin(2 * np.pi * (month - 1) / 12)  # Adjust the seasonality factor as needed\n",
    "        num_ids = int(num_ids * seasonality_factor)\n",
    "\n",
    "        # Generate random IDs, start dates, end dates, mode_of_arrival, and disposition for the current month\n",
    "        for _ in range(num_ids):\n",
    "            day = random.randint(1, 28)  # Generate a random day within the month\n",
    "            start_date = datetime(year, month, day)\n",
    "            end_date = start_date + timedelta(days=random.randint(1, 30))  # Generate a random end date within 30 days\n",
    "            id_value = random.randint(1000000, 99999999)  # Generate 8 digits Patient IDs\n",
    "            arrival_mode = random.choice(mode_of_arrival_options)\n",
    "            gender = random.choice(gender_options)\n",
    "\n",
    "            # Determine if this patient should have a 'Transfer_date'\n",
    "            if transfer_month_distribution[month - 1] > 0:\n",
    "                transfer_date = start_date\n",
    "                transfer_month_distribution[month - 1] -= 1\n",
    "                disposition = 'TRANSFER'\n",
    "            else:\n",
    "                transfer_date = None\n",
    "                disposition = random.choice(disposition_options)\n",
    "\n",
    "            if transfer_date == start_date:\n",
    "                transfer_type = 'Transfer Admissions/Incoming Transfers'\n",
    "            else:\n",
    "                transfer_type = ''\n",
    "\n",
    "            data.append([start_date, end_date, transfer_date, id_value, arrival_mode, disposition, transfer_type, gender])\n",
    "\n",
    "# Create a Pandas DataFrame from the data\n",
    "master_data = pd.DataFrame(data, columns=[\"Admission Date\", \"Discharge Date\", \"Transfer Date\", \"Patient ID\", \"Mode of Arrival\", \"Disposition\", \"Transfer Type\", \"Gender\"])\n",
    "\n",
    "master_data.to_csv('ADT dataset - Streamlit V1.csv')\n",
    "\n",
    "# Assuming 'master_data' is your DataFrame\n",
    "# Convert the 'Admission Date' column to datetime if it's not already\n",
    "master_data['Admission Date'] = pd.to_datetime(master_data['Admission Date'])\n",
    "\n",
    "# Extract the year from the 'Admission Date' column\n",
    "master_data['Year'] = master_data['Admission Date'].dt.year\n",
    "\n",
    "# Group by year and count admissions\n",
    "yearly_admissions = master_data.groupby('Year')['Patient ID'].count()\n",
    "\n",
    "yearly_admissions_percentage_increase = yearly_admissions.pct_change() * 100\n",
    "\n",
    "print(yearly_admissions)\n",
    "# Print the results\n",
    "print(yearly_admissions_percentage_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dbc0791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2015    48878\n",
       "2016    47117\n",
       "2017    51754\n",
       "2018    59118\n",
       "2019    57559\n",
       "2020    61011\n",
       "Name: Patient ID, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data['Admission Date'] = pd.to_datetime(master_data['Admission Date'])\n",
    "\n",
    "# Extract the year from the 'Admission Date' column\n",
    "master_data['Year'] = master_data['Admission Date'].dt.year\n",
    "\n",
    "# Group by year and count admissions\n",
    "yearly_admissions = master_data.groupby('Year')['Patient ID'].count()\n",
    "\n",
    "yearly_admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded3f512",
   "metadata": {},
   "source": [
    "# Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eb5a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "      Admission Date  patient_count\n",
      "1810     2020-11-19             30\n",
      "1811     2020-11-20             30\n",
      "1812     2020-11-21             29\n",
      "1813     2020-11-22             24\n",
      "1814     2020-11-23             31\n",
      "1815     2020-11-24             26\n",
      "1816     2020-11-25             20\n",
      "1817     2020-11-26             26\n",
      "1818     2020-11-27             16\n",
      "1819     2020-11-28             19\n",
      "\n",
      " Training data count:\n",
      " 0       135\n",
      "1       156\n",
      "2       138\n",
      "3       143\n",
      "4       151\n",
      "       ... \n",
      "1815     26\n",
      "1816     20\n",
      "1817     26\n",
      "1818     16\n",
      "1819     19\n",
      "Name: patient_count, Length: 1820, dtype: int64\n",
      "Testing data:\n",
      "    Admission Date  patient_count\n",
      "3      2020-12-19             84\n",
      "4      2020-12-20             95\n",
      "5      2020-12-21             67\n",
      "6      2020-12-22             88\n",
      "7      2020-12-23            106\n",
      "8      2020-12-24             96\n",
      "9      2020-12-25            104\n",
      "10     2020-12-26             98\n",
      "11     2020-12-27             87\n",
      "12     2020-12-28            105\n",
      "\n",
      " Testing data count:\n",
      " 0      91\n",
      "1      77\n",
      "2      92\n",
      "3      84\n",
      "4      95\n",
      "5      67\n",
      "6      88\n",
      "7     106\n",
      "8      96\n",
      "9     104\n",
      "10     98\n",
      "11     87\n",
      "12    105\n",
      "Name: patient_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Training dataset:\n",
    "training_data = master_data[(master_data['Admission Date'] >= '2015-01-01') & (master_data['Admission Date'] <= '2020-11-30')]\n",
    "train_data = training_data.groupby(training_data[\"Admission Date\"])[\"Patient ID\"].count().reset_index()\n",
    "train_data.columns = [\"Admission Date\", \"patient_count\"]\n",
    "print('Training data:\\n',train_data.tail(10))\n",
    "train_df = train_data[\"patient_count\"]\n",
    "train_df.name = \"patient_count\"\n",
    "print('\\n Training data count:\\n',train_df)\n",
    "\n",
    "\n",
    "# Testng dataset:\n",
    "testing_data = master_data[(master_data['Admission Date'] >= '2020-12-16') & (master_data['Admission Date'] <= '2020-12-31')]\n",
    "test_data = testing_data.groupby(testing_data[\"Admission Date\"])[\"Patient ID\"].count().reset_index()\n",
    "test_data.columns = [\"Admission Date\", \"patient_count\"]\n",
    "print('Testing data:\\n',test_data.tail(10))\n",
    "test_df = test_data[\"patient_count\"]\n",
    "test_df.name = \"patient_count\"\n",
    "print('\\n Testing data count:\\n',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2caec887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df\n",
    "test_data = test_df\n",
    "\n",
    "data = train_data\n",
    "\n",
    "# Define the order of the SARIMA model (p, d, q), (P, D, Q, S)\n",
    "# p: AutoRegressive order\n",
    "# d: Differencing order\n",
    "# q: Moving Average order\n",
    "# P: Seasonal AutoRegressive order\n",
    "# D: Seasonal Differencing order\n",
    "# Q: Seasonal Moving Average order\n",
    "# S: Seasonal period (e.g., 12 for monthly data with yearly seasonality)\n",
    "p, d, q = 2, 2, 1\n",
    "P, D, Q, S = 3, 3, 3, 12\n",
    "\n",
    "# Fit the SARIMAX model to your data\n",
    "admissions_model = sm.tsa.SARIMAX(data, order=(p, d, q), seasonal_order=(P, D, Q, S))\n",
    "results = admissions_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f343cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('admission_model1.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66f00743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joblib_model_admissions.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "# save model with joblib \n",
    "filename = 'joblib_model_admissions.sav'\n",
    "joblib.dump(results, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6f0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Define the name of the zip file you want to create\n",
    "zip_filename = 'joblib_model_admissions.zip'\n",
    "\n",
    "# Create a new zip file and add the model file to it\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(filename, arcname=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929dde2",
   "metadata": {},
   "source": [
    "# Discharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a1d8c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2015    47896\n",
       "2016    47167\n",
       "2017    51662\n",
       "2018    58959\n",
       "2019    57650\n",
       "2020    60904\n",
       "2021     1199\n",
       "Name: Patient ID, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data['Discharge Date'] = pd.to_datetime(master_data['Discharge Date'])\n",
    "\n",
    "# Extract the year from the 'Admission Date' column\n",
    "master_data['Year'] = master_data['Discharge Date'].dt.year\n",
    "\n",
    "# Group by year and count admissions\n",
    "yearly_discharges = master_data.groupby('Year')['Patient ID'].count()\n",
    "\n",
    "yearly_discharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2ff274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "   Discharge Date  patient_count\n",
      "0     2015-01-02             12\n",
      "1     2015-01-03              7\n",
      "2     2015-01-04             16\n",
      "3     2015-01-05             16\n",
      "4     2015-01-06             19\n",
      "5     2015-01-07             18\n",
      "6     2015-01-08             32\n",
      "7     2015-01-09             32\n",
      "8     2015-01-10             45\n",
      "9     2015-01-11             46\n",
      "\n",
      " Training data count:\n",
      " 0       135\n",
      "1       156\n",
      "2       138\n",
      "3       143\n",
      "4       151\n",
      "       ... \n",
      "1815     26\n",
      "1816     20\n",
      "1817     26\n",
      "1818     16\n",
      "1819     19\n",
      "Name: patient_count, Length: 1820, dtype: int64\n",
      "Testing data:\n",
      "    Discharge Date  patient_count\n",
      "5      2020-12-22             17\n",
      "6      2020-12-23             17\n",
      "7      2020-12-24             22\n",
      "8      2020-12-25             25\n",
      "9      2020-12-26             25\n",
      "10     2020-12-27             45\n",
      "11     2020-12-28             39\n",
      "12     2020-12-29             40\n",
      "13     2020-12-30             33\n",
      "14     2020-12-31             30\n",
      "\n",
      " Testing data count:\n",
      " 0      91\n",
      "1      77\n",
      "2      92\n",
      "3      84\n",
      "4      95\n",
      "5      67\n",
      "6      88\n",
      "7     106\n",
      "8      96\n",
      "9     104\n",
      "10     98\n",
      "11     87\n",
      "12    105\n",
      "Name: patient_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Training dataset:\n",
    "training_data_discharge = master_data[(master_data['Discharge Date'] >= '2015-01-01') & (master_data['Discharge Date'] <= '2020-11-30')]\n",
    "train_data_discharge = training_data_discharge.groupby(training_data[\"Discharge Date\"])[\"Patient ID\"].count().reset_index()\n",
    "train_data_discharge.columns = [\"Discharge Date\", \"patient_count\"]\n",
    "print('Training data:\\n',train_data_discharge.head(10))\n",
    "train_df_discharge = train_data_discharge[\"patient_count\"]\n",
    "train_df_discharge.name = \"patient_count\"\n",
    "print('\\n Training data count:\\n',train_df)\n",
    "\n",
    "\n",
    "# Testng dataset:\n",
    "testing_data_discharge = master_data[(master_data['Discharge Date'] >= '2020-12-01') & (master_data['Discharge Date'] <= '2020-12-31')]\n",
    "test_data_discharge = testing_data_discharge.groupby(testing_data[\"Discharge Date\"])[\"Patient ID\"].count().reset_index()\n",
    "test_data_discharge.columns = [\"Discharge Date\", \"patient_count\"]\n",
    "print('Testing data:\\n',test_data_discharge.tail(10))\n",
    "test_df_discharge = test_data_discharge[\"patient_count\"]\n",
    "test_df_discharge.name = \"patient_count\"\n",
    "print('\\n Testing data count:\\n',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "677323c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df_discharge\n",
    "test_data = test_df_discharge\n",
    "\n",
    "# Load your time series data into a pandas DataFrame\n",
    "# Replace 'your_data.csv' with your data file\n",
    "#data = pd.read_csv('ADT datset V1.csv')\n",
    "#data['Date'] = pd.to_datetime(data['Date'])  # Make sure the 'Date' column is in datetime format\n",
    "#data.set_index('Date', inplace=True)  # Set 'Date' as the index\n",
    "\n",
    "data = train_data\n",
    "\n",
    "# Define the order of the SARIMA model (p, d, q), (P, D, Q, S)\n",
    "# p: AutoRegressive order\n",
    "# d: Differencing order\n",
    "# q: Moving Average order\n",
    "# P: Seasonal AutoRegressive order\n",
    "# D: Seasonal Differencing order\n",
    "# Q: Seasonal Moving Average order\n",
    "# S: Seasonal period (e.g., 12 for monthly data with yearly seasonality)\n",
    "p, d, q = 2, 2, 3\n",
    "P, D, Q, S = 3, 3, 3, 12\n",
    "\n",
    "# Fit the SARIMAX model to your data\n",
    "model = sm.tsa.SARIMAX(data, order=(p, d, q), seasonal_order=(P, D, Q, S))\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13985c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('discharge_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32581d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "# save model with joblib \n",
    "filename = 'joblib_model_discharge.sav'\n",
    "joblib.dump(result, filename)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Define the name of the zip file you want to create\n",
    "zip_filename = 'joblib_model_discharge.zip'\n",
    "\n",
    "# Create a new zip file and add the model file to it\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(filename, arcname=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff48d2a",
   "metadata": {},
   "source": [
    "# Transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data['Transfer Date'] = pd.to_datetime(master_data['Transfer Date'])\n",
    "\n",
    "# Extract the year from the 'Admission Date' column\n",
    "master_data['Year'] = master_data['Transfer Date'].dt.year\n",
    "\n",
    "# Group by year and count admissions\n",
    "yearly_transfers = master_data.groupby('Year')['Patient ID'].count()\n",
    "\n",
    "yearly_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset:\n",
    "training_data_transfer = master_data[(master_data['Transfer Date'] >= '2019-01-01') & (master_data['Transfer Date'] <= '2020-11-30')]\n",
    "train_data_transfer = training_data_transfer.groupby(training_data[\"Transfer Date\"])[\"Patient ID\"].count().reset_index()\n",
    "train_data_transfer.columns = [\"Transfer Date\", \"patient_count\"]\n",
    "print('Training data:\\n',train_data_transfer.head(10))\n",
    "train_df_transfer = train_data_transfer[\"patient_count\"]\n",
    "train_df_transfer.name = \"patient_count\"\n",
    "print('\\n Training data count:\\n',train_df)\n",
    "\n",
    "\n",
    "# Testng dataset:\n",
    "testing_data_transfer = master_data[(master_data['Transfer Date'] >= '2020-12-01') & (master_data['Transfer Date'] <= '2020-12-31')]\n",
    "test_data_transfer = testing_data_transfer.groupby(testing_data_transfer[\"Transfer Date\"])[\"Patient ID\"].count().reset_index()\n",
    "test_data_transfer.columns = [\"Transfer Date\", \"patient_count\"]\n",
    "print('Testing data:\\n',test_data_transfer.tail(10))\n",
    "test_df_transfer = test_data_transfer[\"patient_count\"]\n",
    "test_df_transfer.name = \"patient_count\"\n",
    "print('\\n Testing data count:\\n',test_df_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df_transfer\n",
    "test_data = test_df_transfer\n",
    "\n",
    "# Load your time series data into a pandas DataFrame\n",
    "# Replace 'your_data.csv' with your data file\n",
    "#data = pd.read_csv('ADT datset V1.csv')\n",
    "#data['Date'] = pd.to_datetime(data['Date'])  # Make sure the 'Date' column is in datetime format\n",
    "#data.set_index('Date', inplace=True)  # Set 'Date' as the index\n",
    "\n",
    "data = train_data\n",
    "\n",
    "# Define the order of the SARIMA model (p, d, q), (P, D, Q, S)\n",
    "# p: AutoRegressive order\n",
    "# d: Differencing order\n",
    "# q: Moving Average order\n",
    "# P: Seasonal AutoRegressive order\n",
    "# D: Seasonal Differencing order\n",
    "# Q: Seasonal Moving Average order\n",
    "# S: Seasonal period (e.g., 12 for monthly data with yearly seasonality)\n",
    "p, d, q = 2, 2, 2\n",
    "P, D, Q, S = 2, 2, 2, 12\n",
    "\n",
    "# Fit the SARIMAX model to your data\n",
    "model = sm.tsa.SARIMAX(data, order=(p, d, q), seasonal_order=(P, D, Q, S))\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a20b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transfer_model1.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "# save model with joblib \n",
    "filename = 'joblib_model_transfer.sav'\n",
    "joblib.dump(result, filename)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Define the name of the zip file you want to create\n",
    "zip_filename = 'joblib_model_transfer.zip'\n",
    "\n",
    "# Create a new zip file and add the model file to it\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(filename, arcname=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acef6df",
   "metadata": {},
   "source": [
    "## Creating forecast data set for next 3 months "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca3721c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Replace 'your_file.pkl' with the path to your actual pickle file\n",
    "file_path = 'admissions_model.pkl'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the content of the file into a Python object\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35b81cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37896"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')\n",
    "forecast_results = data.get_forecast(steps=len(date_range))\n",
    "forecast_mean = forecast_results.predicted_mean\n",
    "admissions_forecast_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(date_range).date,\n",
    "    'Forecasted Admissions Count': np.ceil(forecast_mean).astype(int)            \n",
    "                })\n",
    "total_admissions = admissions_forecast_data['Forecasted Admissions Count'].sum()\n",
    "total_admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "729d92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_forecast_data.to_csv('admissions_forecast_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed29dfd4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8851\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Forecasted Discharge Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Forecasted Discharge Count\n",
       "2128  2024-01-01                          15\n",
       "2129  2024-01-02                           7\n",
       "2130  2024-01-03                          17\n",
       "2131  2024-01-04                           9\n",
       "2132  2024-01-05                          24\n",
       "...          ...                         ...\n",
       "2214  2024-03-27                         189\n",
       "2215  2024-03-28                         177\n",
       "2216  2024-03-29                         197\n",
       "2217  2024-03-30                         229\n",
       "2218  2024-03-31                         229\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the path to your actual pickle file\n",
    "file_path = 'discharge_model.pkl'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the content of the file into a Python object\n",
    "    data1 = pickle.load(file)\n",
    "    \n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')\n",
    "forecast_results = data1.get_forecast(steps=len(date_range))\n",
    "forecast_mean = forecast_results.predicted_mean\n",
    "discharge_forecast_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(date_range).date,\n",
    "    'Forecasted Discharge Count': np.ceil(forecast_mean).astype(int)            \n",
    "                })\n",
    "total_discharges = discharge_forecast_data['Forecasted Discharge Count'].sum()\n",
    "print(total_discharges)\n",
    "discharge_forecast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89664e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_forecast_data.to_csv('discharge_forecast_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0ffca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the path to your actual pickle file\n",
    "file_path = 'transfer_model.pkl'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the content of the file into a Python object\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')\n",
    "forecast_results = data.get_forecast(steps=len(date_range))\n",
    "forecast_mean = forecast_results.predicted_mean\n",
    "transfer_forecast_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(date_range).date,\n",
    "    'Forecasted Transfer Count': np.ceil(forecast_mean).astype(int)            \n",
    "                })\n",
    "total_transfer = transfer_forecast_data['Forecasted Transfer Count'].sum()\n",
    "print(total_transfer)\n",
    "transfer_forecast_data.to_csv('transfer_forecast_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0002ca91",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Forecasted Transfer Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Forecasted Transfer Count\n",
       "1814  2024-01-01                          8\n",
       "1815  2024-01-02                          7\n",
       "1816  2024-01-03                          8\n",
       "1817  2024-01-04                          7\n",
       "1818  2024-01-05                          8\n",
       "...          ...                        ...\n",
       "1900  2024-03-27                          6\n",
       "1901  2024-03-28                          6\n",
       "1902  2024-03-29                          6\n",
       "1903  2024-03-30                          5\n",
       "1904  2024-03-31                          6\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_forecast_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196875f3",
   "metadata": {},
   "source": [
    "## For Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53403700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly.graph_objects as go\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05e3cc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully\n",
      "Dataframe shape: (1826, 2)\n"
     ]
    }
   ],
   "source": [
    "# Database connection parameters\n",
    "db_name = 'factihealth'   # Database name\n",
    "db_user = 'fh_user'  # Username\n",
    "db_password = 'Facti@874'  # Password\n",
    "db_host = 'redshift-cluster-factihealth.cuzgotkwtow6.ap-south-1.redshift.amazonaws.com'  # Cluster endpoint\n",
    "db_port = 5439  # Port\n",
    "# Connect to the database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        host=db_host,\n",
    "        port=db_port\n",
    "    )\n",
    "    print(\"Connected to the database successfully\")\n",
    "    # Create a cursor object\n",
    "    cur = conn.cursor()\n",
    "    # Execute a query\n",
    "    cur.execute('''select admittime::DATE as admittime_date, count(distinct subject_id) from factihealth.mimic.admissions \n",
    "where date_part(year,admittime) in (2125,2126,2127,2128,2129)\n",
    "group by admittime_date\n",
    "order by admittime_date''')\n",
    "    # Fetch the result\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    # Get the column names\n",
    "    column_names = [desc[0] for desc in cur.description]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    master_data = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    print('Dataframe shape:', master_data.shape)\n",
    "    # Fetch and print the result\n",
    "except Exception as e:\n",
    "    print(f\"Database connection failed due to {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b3b67c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "      admittime_date  count\n",
      "1785     2129-11-21     17\n",
      "1786     2129-11-22     20\n",
      "1787     2129-11-23      9\n",
      "1788     2129-11-24     16\n",
      "1789     2129-11-25     10\n",
      "1790     2129-11-26     21\n",
      "1791     2129-11-27     16\n",
      "1792     2129-11-28     13\n",
      "1793     2129-11-29     15\n",
      "1794     2129-11-30     15\n",
      "\n",
      " Training data count:\n",
      " 0       19\n",
      "1        8\n",
      "2       17\n",
      "3       19\n",
      "4       15\n",
      "        ..\n",
      "1790    21\n",
      "1791    16\n",
      "1792    13\n",
      "1793    15\n",
      "1794    15\n",
      "Name: count, Length: 1795, dtype: int64\n",
      "Testing data:\n",
      "      admittime_date  count\n",
      "1816     2129-12-22     16\n",
      "1817     2129-12-23     13\n",
      "1818     2129-12-24     17\n",
      "1819     2129-12-25     15\n",
      "1820     2129-12-26     14\n",
      "1821     2129-12-27     14\n",
      "1822     2129-12-28     12\n",
      "1823     2129-12-29     13\n",
      "1824     2129-12-30     14\n",
      "1825     2129-12-31     16\n",
      "\n",
      " Testing data count:\n",
      " 1795    15\n",
      "1796    16\n",
      "1797    14\n",
      "1798    14\n",
      "1799    14\n",
      "1800    11\n",
      "1801    13\n",
      "1802    19\n",
      "1803    10\n",
      "1804    15\n",
      "1805    13\n",
      "1806    13\n",
      "1807    13\n",
      "1808    11\n",
      "1809    20\n",
      "1810    13\n",
      "1811    12\n",
      "1812     9\n",
      "1813    11\n",
      "1814    17\n",
      "1815    14\n",
      "1816    16\n",
      "1817    13\n",
      "1818    17\n",
      "1819    15\n",
      "1820    14\n",
      "1821    14\n",
      "1822    12\n",
      "1823    13\n",
      "1824    14\n",
      "1825    16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Training dataset:\n",
    "master_data['admittime_date'] = pd.to_datetime(master_data['admittime_date'])\n",
    "\n",
    "# Filter rows where 'admittime_date' falls within the specified range\n",
    "train_data = master_data[\n",
    "    (master_data['admittime_date'] >= '2125-01-01') & \n",
    "    (master_data['admittime_date'] <= '2129-11-30')\n",
    "]\n",
    "\n",
    "#training_data = master_data[(master_data['admittime_date'] >= '2125-01-01') & (master_data['admittime_date'] <= '2129-11-30')]\n",
    "train_data.columns = [\"admittime_date\", \"count\"]\n",
    "print('Training data:\\n',train_data.tail(10))\n",
    "train_df = train_data[\"count\"]\n",
    "train_df.name = \"count\"\n",
    "print('\\n Training data count:\\n',train_df)\n",
    "\n",
    "\n",
    "# Testng dataset:\n",
    "\n",
    "# Filter rows where 'admittime_date' falls within the specified range\n",
    "test_data = master_data[\n",
    "    (master_data['admittime_date'] >= '2129-12-01') & \n",
    "    (master_data['admittime_date'] <= '2129-12-31')\n",
    "]\n",
    "test_data.columns = [\"admittime_date\", \"count\"]\n",
    "print('Testing data:\\n',test_data.tail(10))\n",
    "test_df = test_data[\"count\"]\n",
    "test_df.name = \"count\"\n",
    "print('\\n Testing data count:\\n',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9ebe4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df\n",
    "test_data = test_df\n",
    "\n",
    "data = train_data\n",
    "\n",
    "p, d, q = 2, 2, 1\n",
    "P, D, Q, S = 3, 3, 3, 12\n",
    "\n",
    "# Fit the SARIMAX model to your data\n",
    "admissions_model = sm.tsa.SARIMAX(data, order=(p, d, q), seasonal_order=(P, D, Q, S))\n",
    "results = admissions_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9a01d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasted Values: 1795    11.0\n",
      "1796    23.0\n",
      "1797    17.0\n",
      "1798    24.0\n",
      "1799     9.0\n",
      "1800    14.0\n",
      "1801     8.0\n",
      "1802    22.0\n",
      "1803    10.0\n",
      "1804    12.0\n",
      "Name: predicted_mean, dtype: float64\n",
      "Confidence Intervals:       lower count  upper count\n",
      "1795    -2.507416    23.593652\n",
      "1796     8.805640    36.225998\n",
      "1797     1.628171    31.826149\n",
      "1798     6.262881    40.041522\n",
      "1799    -9.572277    26.350042\n",
      "1800    -5.756170    32.623030\n",
      "1801   -12.590305    28.115848\n",
      "1802    -0.228898    42.563011\n",
      "1803   -12.899490    31.967315\n",
      "1804   -11.892571    34.948295\n"
     ]
    }
   ],
   "source": [
    "# Forecast the next 10 time points\n",
    "forecast = results.get_forecast(steps=10)\n",
    "\n",
    "# Get the forecasted values and confidence intervals\n",
    "forecasted_values = forecast.predicted_mean\n",
    "confidence_intervals = forecast.conf_int()\n",
    "\n",
    "print(\"Forecasted Values:\", np.ceil(forecasted_values))\n",
    "print(\"Confidence Intervals:\", confidence_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74baac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('admission_model_demo.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0bc1d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Forecasted Admissions Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Forecasted Admissions Count\n",
       "1795  2024-01-01                           11\n",
       "1796  2024-01-02                           23\n",
       "1797  2024-01-03                           17\n",
       "1798  2024-01-04                           24\n",
       "1799  2024-01-05                            9\n",
       "...          ...                          ...\n",
       "1881  2024-03-27                           -1\n",
       "1882  2024-03-28                           44\n",
       "1883  2024-03-29                           -3\n",
       "1884  2024-03-30                           20\n",
       "1885  2024-03-31                            0\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the path to your actual pickle file\n",
    "file_path = 'admission_model_demo.pkl'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the content of the file into a Python object\n",
    "    data1 = pickle.load(file)\n",
    "    \n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')\n",
    "\n",
    "forecast_results = data1.get_forecast(steps=len(date_range))\n",
    "forecast_mean = forecast_results.predicted_mean\n",
    "forecast_mean_non_negative = np.abs(forecast_mean)\n",
    "admissions_forecast_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(date_range).date,\n",
    "    'Forecasted Admissions Count': np.ceil(forecast_mean).astype(int)            \n",
    "                })\n",
    "total_admissions = admissions_forecast_data['Forecasted Admissions Count'].sum()\n",
    "print(total_admissions)\n",
    "admissions_forecast_data.to_csv('admissions_forecast_data.csv')\n",
    "admissions_forecast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f12eb02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully\n",
      "Dataframe shape: (1826, 2)\n"
     ]
    }
   ],
   "source": [
    "# Database connection parameters\n",
    "db_name = 'factihealth'   # Database name\n",
    "db_user = 'fh_user'  # Username\n",
    "db_password = 'Facti@874'  # Password\n",
    "db_host = 'redshift-cluster-factihealth.cuzgotkwtow6.ap-south-1.redshift.amazonaws.com'  # Cluster endpoint\n",
    "db_port = 5439  # Port\n",
    "# Connect to the database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        host=db_host,\n",
    "        port=db_port\n",
    "    )\n",
    "    print(\"Connected to the database successfully\")\n",
    "    # Create a cursor object\n",
    "    cur = conn.cursor()\n",
    "    # Execute a query\n",
    "    cur.execute('''select dischtime::DATE as dischtime_date, count(distinct subject_id) from factihealth.mimic.admissions \n",
    "where date_part(year,dischtime) in (2125,2126,2127,2128,2129)\n",
    "group by dischtime_date\n",
    "order by dischtime_date''')\n",
    "    # Fetch the result\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    # Get the column names\n",
    "    column_names = [desc[0] for desc in cur.description]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    master_data = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    print('Dataframe shape:', master_data.shape)\n",
    "    # Fetch and print the result\n",
    "except Exception as e:\n",
    "    print(f\"Database connection failed due to {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dab7a4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "      dischtime_date  count\n",
      "1785     2129-11-21     11\n",
      "1786     2129-11-22     13\n",
      "1787     2129-11-23     19\n",
      "1788     2129-11-24     22\n",
      "1789     2129-11-25     24\n",
      "1790     2129-11-26      7\n",
      "1791     2129-11-27     18\n",
      "1792     2129-11-28     15\n",
      "1793     2129-11-29     15\n",
      "1794     2129-11-30     12\n",
      "\n",
      " Training data count:\n",
      " 0       10\n",
      "1       17\n",
      "2       18\n",
      "3       11\n",
      "4       20\n",
      "        ..\n",
      "1790     7\n",
      "1791    18\n",
      "1792    15\n",
      "1793    15\n",
      "1794    12\n",
      "Name: count, Length: 1795, dtype: int64\n",
      "Testing data:\n",
      "      dischtime_date  count\n",
      "1816     2129-12-22     16\n",
      "1817     2129-12-23     14\n",
      "1818     2129-12-24     13\n",
      "1819     2129-12-25     20\n",
      "1820     2129-12-26     11\n",
      "1821     2129-12-27     12\n",
      "1822     2129-12-28     15\n",
      "1823     2129-12-29     17\n",
      "1824     2129-12-30     12\n",
      "1825     2129-12-31     16\n",
      "\n",
      " Testing data count:\n",
      " 1795     7\n",
      "1796    16\n",
      "1797    17\n",
      "1798    13\n",
      "1799    17\n",
      "1800    14\n",
      "1801    11\n",
      "1802    16\n",
      "1803    13\n",
      "1804    14\n",
      "1805    14\n",
      "1806     8\n",
      "1807    11\n",
      "1808    17\n",
      "1809    15\n",
      "1810    12\n",
      "1811    21\n",
      "1812    11\n",
      "1813    12\n",
      "1814     7\n",
      "1815     9\n",
      "1816    16\n",
      "1817    14\n",
      "1818    13\n",
      "1819    20\n",
      "1820    11\n",
      "1821    12\n",
      "1822    15\n",
      "1823    17\n",
      "1824    12\n",
      "1825    16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Training dataset:\n",
    "master_data['dischtime_date'] = pd.to_datetime(master_data['dischtime_date'])\n",
    "\n",
    "# Filter rows where 'admittime_date' falls within the specified range\n",
    "train_data = master_data[\n",
    "    (master_data['dischtime_date'] >= '2125-01-01') & \n",
    "    (master_data['dischtime_date'] <= '2129-11-30')\n",
    "]\n",
    "\n",
    "#training_data = master_data[(master_data['admittime_date'] >= '2125-01-01') & (master_data['admittime_date'] <= '2129-11-30')]\n",
    "train_data.columns = [\"dischtime_date\", \"count\"]\n",
    "print('Training data:\\n',train_data.tail(10))\n",
    "train_df = train_data[\"count\"]\n",
    "train_df.name = \"count\"\n",
    "print('\\n Training data count:\\n',train_df)\n",
    "\n",
    "\n",
    "# Testng dataset:\n",
    "\n",
    "# Filter rows where 'admittime_date' falls within the specified range\n",
    "test_data = master_data[\n",
    "    (master_data['dischtime_date'] >= '2129-12-01') & \n",
    "    (master_data['dischtime_date'] <= '2129-12-31')\n",
    "]\n",
    "test_data.columns = [\"dischtime_date\", \"count\"]\n",
    "print('Testing data:\\n',test_data.tail(10))\n",
    "test_df = test_data[\"count\"]\n",
    "test_df.name = \"count\"\n",
    "print('\\n Testing data count:\\n',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d6de26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df\n",
    "test_data = test_df\n",
    "\n",
    "data = train_data\n",
    "\n",
    "p, d, q = 2, 2, 1\n",
    "P, D, Q, S = 3, 3, 3, 12\n",
    "\n",
    "# Fit the SARIMAX model to your data\n",
    "discharge_model = sm.tsa.SARIMAX(data, order=(p, d, q), seasonal_order=(P, D, Q, S))\n",
    "results = discharge_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52145ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('discharge_model_demo.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4aef1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Forecasted Discharge Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Forecasted Discharge Count\n",
       "1795  2024-01-01                          14\n",
       "1796  2024-01-02                          22\n",
       "1797  2024-01-03                          19\n",
       "1798  2024-01-04                          17\n",
       "1799  2024-01-05                          20\n",
       "...          ...                         ...\n",
       "1881  2024-03-27                          48\n",
       "1882  2024-03-28                          62\n",
       "1883  2024-03-29                          60\n",
       "1884  2024-03-30                          92\n",
       "1885  2024-03-31                         108\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the path to your actual pickle file\n",
    "file_path = 'discharge_model_demo.pkl'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the content of the file into a Python object\n",
    "    data1 = pickle.load(file)\n",
    "    \n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')\n",
    "forecast_results = data1.get_forecast(steps=len(date_range))\n",
    "forecast_mean = forecast_results.predicted_mean\n",
    "forecast_mean_non_negative = np.abs(forecast_mean)\n",
    "discharge_forecast_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(date_range).date,\n",
    "    'Forecasted Discharge Count': np.ceil(forecast_mean).astype(int)            \n",
    "                })\n",
    "total_discharges = discharge_forecast_data['Forecasted Discharge Count'].sum()\n",
    "print(total_discharges)\n",
    "discharge_forecast_data.to_csv('discharge_forecast_data.csv')\n",
    "discharge_forecast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56eac43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasted Values: 1795    14.0\n",
      "1796    22.0\n",
      "1797    19.0\n",
      "1798    17.0\n",
      "1799    20.0\n",
      "1800    27.0\n",
      "1801    28.0\n",
      "1802     8.0\n",
      "1803    24.0\n",
      "1804    21.0\n",
      "Name: predicted_mean, dtype: float64\n",
      "Confidence Intervals:       lower count  upper count\n",
      "1795     0.690229    27.107860\n",
      "1796     7.500657    34.959116\n",
      "1797     3.092128    33.140262\n",
      "1798    -0.233478    33.472914\n",
      "1799     1.875710    37.497695\n",
      "1800     7.741986    45.741206\n",
      "1801     7.404748    47.672463\n",
      "1802   -13.489176    28.743457\n",
      "1803     0.932666    45.173648\n",
      "1804    -2.536540    43.606120\n"
     ]
    }
   ],
   "source": [
    "# Forecast the next 10 time points\n",
    "forecast = results.get_forecast(steps=10)\n",
    "\n",
    "# Get the forecasted values and confidence intervals\n",
    "forecasted_values = forecast.predicted_mean\n",
    "confidence_intervals = forecast.conf_int()\n",
    "\n",
    "print(\"Forecasted Values:\", np.ceil(forecasted_values))\n",
    "print(\"Confidence Intervals:\", confidence_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db05f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully\n",
      "Dataframe shape: (1374, 2)\n"
     ]
    }
   ],
   "source": [
    "# Database connection parameters\n",
    "db_name = 'factihealth'   # Database name\n",
    "db_user = 'fh_user'  # Username\n",
    "db_password = 'Facti@874'  # Password\n",
    "db_host = 'redshift-cluster-factihealth.cuzgotkwtow6.ap-south-1.redshift.amazonaws.com'  # Cluster endpoint\n",
    "db_port = 5439  # Port\n",
    "# Connect to the database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        host=db_host,\n",
    "        port=db_port\n",
    "    )\n",
    "    print(\"Connected to the database successfully\")\n",
    "    # Create a cursor object\n",
    "    cur = conn.cursor()\n",
    "    # Execute a query\n",
    "    cur.execute('''select transtime:: Date as transtime_date, count(distinct subject_id)\n",
    "                    from\n",
    "                    (\n",
    "                    select distinct subject_id,\n",
    "                    case \n",
    "                        when (lower(admission_location) like '%transfer%') then admittime\n",
    "                        when (lower(admission_location) not like '%transfer%') then null \n",
    "                    end as transtime\n",
    "                    from factihealth.mimic.admissions \n",
    "                    where date_part(year,admittime) in (2125,2126,2127,2128,2129)\n",
    "                    )\n",
    "                    group by transtime_date\n",
    "                    order by transtime_date\n",
    "                    ''')\n",
    "    # Fetch the result\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    # Get the column names\n",
    "    column_names = [desc[0] for desc in cur.description]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    master_data = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    print('Dataframe shape:', master_data.shape)\n",
    "    # Fetch and print the result\n",
    "except Exception as e:\n",
    "    print(f\"Database connection failed due to {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f60c12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "      transtime_date  count\n",
      "1337     2129-11-20      1\n",
      "1338     2129-11-21      1\n",
      "1339     2129-11-22      1\n",
      "1340     2129-11-23      1\n",
      "1341     2129-11-24      2\n",
      "1342     2129-11-25      1\n",
      "1343     2129-11-26      1\n",
      "1344     2129-11-28      1\n",
      "1345     2129-11-29      2\n",
      "1346     2129-11-30      1\n",
      "\n",
      " Training data count:\n",
      " 0       1\n",
      "1       1\n",
      "2       2\n",
      "3       6\n",
      "4       1\n",
      "       ..\n",
      "1342    1\n",
      "1343    1\n",
      "1344    1\n",
      "1345    2\n",
      "1346    1\n",
      "Name: count, Length: 1347, dtype: int64\n",
      "Testing data:\n",
      "      transtime_date  count\n",
      "1363     2129-12-20      1\n",
      "1364     2129-12-21      1\n",
      "1365     2129-12-22      1\n",
      "1366     2129-12-23      2\n",
      "1367     2129-12-24      2\n",
      "1368     2129-12-26      3\n",
      "1369     2129-12-27      1\n",
      "1370     2129-12-29      2\n",
      "1371     2129-12-30      1\n",
      "1372     2129-12-31      4\n",
      "\n",
      " Testing data count:\n",
      " 1347    2\n",
      "1348    1\n",
      "1349    2\n",
      "1350    2\n",
      "1351    1\n",
      "1352    1\n",
      "1353    1\n",
      "1354    1\n",
      "1355    4\n",
      "1356    2\n",
      "1357    2\n",
      "1358    1\n",
      "1359    3\n",
      "1360    1\n",
      "1361    1\n",
      "1362    1\n",
      "1363    1\n",
      "1364    1\n",
      "1365    1\n",
      "1366    2\n",
      "1367    2\n",
      "1368    3\n",
      "1369    1\n",
      "1370    2\n",
      "1371    1\n",
      "1372    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Training dataset:\n",
    "master_data['transtime_date'] = pd.to_datetime(master_data['transtime_date'])\n",
    "\n",
    "# Filter rows where 'admittime_date' falls within the specified range\n",
    "train_data = master_data[\n",
    "    (master_data['transtime_date'] >= '2125-01-01') & \n",
    "    (master_data['transtime_date'] <= '2129-11-30')\n",
    "]\n",
    "\n",
    "#training_data = master_data[(master_data['admittime_date'] >= '2125-01-01') & (master_data['admittime_date'] <= '2129-11-30')]\n",
    "train_data.columns = [\"transtime_date\", \"count\"]\n",
    "print('Training data:\\n',train_data.tail(10))\n",
    "train_df = train_data[\"count\"]\n",
    "train_df.name = \"count\"\n",
    "print('\\n Training data count:\\n',train_df)\n",
    "\n",
    "\n",
    "# Testng dataset:\n",
    "\n",
    "# Filter rows where 'admittime_date' falls within the specified range\n",
    "test_data = master_data[\n",
    "    (master_data['transtime_date'] >= '2129-12-01') & \n",
    "    (master_data['transtime_date'] <= '2129-12-31')\n",
    "]\n",
    "test_data.columns = [\"transtime_date\", \"count\"]\n",
    "print('Testing data:\\n',test_data.tail(10))\n",
    "test_df = test_data[\"count\"]\n",
    "test_df.name = \"count\"\n",
    "print('\\n Testing data count:\\n',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab927f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df\n",
    "test_data = test_df\n",
    "\n",
    "data = train_data\n",
    "\n",
    "p, d, q = 2, 2, 1\n",
    "P, D, Q, S = 3, 3, 3, 12\n",
    "\n",
    "# Fit the SARIMAX model to your data\n",
    "transfer_model = sm.tsa.SARIMAX(data, order=(p, d, q), seasonal_order=(P, D, Q, S))\n",
    "results = transfer_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28474db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transfer_model_demo.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fedf400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Forecasted Transfer Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Forecasted Transfer Count\n",
       "1347  2024-01-01                          3\n",
       "1348  2024-01-02                          3\n",
       "1349  2024-01-03                          0\n",
       "1350  2024-01-04                          1\n",
       "1351  2024-01-05                          0\n",
       "...          ...                        ...\n",
       "1433  2024-03-27                        -20\n",
       "1434  2024-03-28                        -26\n",
       "1435  2024-03-29                        -24\n",
       "1436  2024-03-30                        -18\n",
       "1437  2024-03-31                        -13\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the path to your actual pickle file\n",
    "file_path = 'transfer_model_demo.pkl'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the content of the file into a Python object\n",
    "    data1 = pickle.load(file)\n",
    "    \n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')\n",
    "forecast_results = data1.get_forecast(steps=len(date_range))\n",
    "forecast_mean = forecast_results.predicted_mean\n",
    "forecast_mean_non_negative = np.abs(forecast_mean)\n",
    "transfer_forecast_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(date_range).date,\n",
    "    'Forecasted Transfer Count': np.ceil(forecast_mean).astype(int)            \n",
    "                })\n",
    "total_transfers = transfer_forecast_data['Forecasted Transfer Count'].sum()\n",
    "print(total_transfers)\n",
    "transfer_forecast_data.to_csv('transfer_forecast_data.csv')\n",
    "transfer_forecast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b81a445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasted Values: 1347    3.0\n",
      "1348    3.0\n",
      "1349   -0.0\n",
      "1350    1.0\n",
      "1351   -0.0\n",
      "1352    1.0\n",
      "1353    2.0\n",
      "1354   -0.0\n",
      "1355   -0.0\n",
      "1356   -1.0\n",
      "Name: predicted_mean, dtype: float64\n",
      "Confidence Intervals:       lower count  upper count\n",
      "1347    -1.494822     5.565584\n",
      "1348    -1.611601     5.999187\n",
      "1349    -4.713862     3.541842\n",
      "1350    -4.650242     4.666838\n",
      "1351    -5.597146     4.375544\n",
      "1352    -4.489725     6.142619\n",
      "1353    -4.166896     7.146756\n",
      "1354    -6.763642     5.151921\n",
      "1355    -6.595819     5.905250\n",
      "1356    -8.453088     4.617436\n"
     ]
    }
   ],
   "source": [
    "# Forecast the next 10 time points\n",
    "forecast = results.get_forecast(steps=10)\n",
    "\n",
    "# Get the forecasted values and confidence intervals\n",
    "forecasted_values = forecast.predicted_mean\n",
    "confidence_intervals = forecast.conf_int()\n",
    "\n",
    "print(\"Forecasted Values:\", np.ceil(forecasted_values))\n",
    "print(\"Confidence Intervals:\", confidence_intervals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
