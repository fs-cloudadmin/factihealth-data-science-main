{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00008884",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook documents the process of developing a machine learning model for predicting gout occurrence using data in the Amazon SageMaker environment. Gout is a type of arthritis caused by the buildup of uric acid crystals in the joints, leading to inflammation and pain. By leveraging machine learning techniques, we aim to predict the likelihood of gout in individuals based on various features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacd419",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6edcb0c",
   "metadata": {},
   "source": [
    "### !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "!pip install imblearn\n",
    "!pip install xgboost\n",
    "!pip install scikit-learn==1.2.1\n",
    "!pip install xgboost==1.7.1\n",
    "!pip install sagemaker psycopg2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ffd1c43",
   "metadata": {},
   "source": [
    "!pip install sagemaker psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1ca9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "# import spacy\n",
    "import time \n",
    "# Load spaCy's English model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from predict_and_decode import PredictAndDecode\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "725f531f",
   "metadata": {},
   "source": [
    "!pip install imblearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b02c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d58bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\sourodeep.das\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\sourodeep.das\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848318c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4357612",
   "metadata": {},
   "source": [
    "# DB Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecb61dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connection(query):\n",
    "    # Database connection parameters\n",
    "    db_name = 'factihealth'   # Database name\n",
    "    db_user = 'fh_user'  # Username\n",
    "    db_password = 'Facti@874'  # Password\n",
    "    db_host = 'redshift-cluster-factihealth.cuzgotkwtow6.ap-south-1.redshift.amazonaws.com'  # Cluster endpoint\n",
    "    db_port = 5439  # Port\n",
    "    \n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            host=db_host,\n",
    "            port=db_port\n",
    "        )\n",
    "        print(\"Connected to the database successfully\")\n",
    "        \n",
    "        # Create a cursor object\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Execute a query\n",
    "        cur.execute(query)\n",
    "        \n",
    "        # Fetch all rows\n",
    "        rows = cur.fetchall()\n",
    "        \n",
    "        if not rows:\n",
    "            print(\"No rows returned from the query.\")\n",
    "            return None\n",
    "\n",
    "        # Get column names from the cursor description\n",
    "        col_names = [desc[0] for desc in cur.description]\n",
    "        \n",
    "        # Create a DataFrame from the fetched rows and column names\n",
    "        df = pd.DataFrame(rows, columns=col_names)\n",
    "        \n",
    "        # Close the cursor and connection\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Database connection failed due to {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07384e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chief_complaint</th>\n",
       "      <th>predict</th>\n",
       "      <th>consensus</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>stepped on a nail at home with right foot, pai...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8433</th>\n",
       "      <td>\" I was having a breakdown.\" R/T stress and de...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>\"I tried to jump in front of a car\" Pt states ...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8435</th>\n",
       "      <td>Abdominal pain x 1 week. Denies PMH</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>Rash/sores across body, infection ro left thum...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        chief_complaint predict consensus  \\\n",
       "8432  stepped on a nail at home with right foot, pai...       N         N   \n",
       "8433  \" I was having a breakdown.\" R/T stress and de...       N         -   \n",
       "8434  \"I tried to jump in front of a car\" Pt states ...       N         -   \n",
       "8435                Abdominal pain x 1 week. Denies PMH       N         -   \n",
       "8436  Rash/sores across body, infection ro left thum...       N         N   \n",
       "\n",
       "      year  \n",
       "8432  2020  \n",
       "8433  2020  \n",
       "8434  2020  \n",
       "8435  2020  \n",
       "8436  2020  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "query = 'Select * from mimic.gout_corpus'\n",
    "data = db_connection(query)\n",
    "dataset = data.copy(deep=True)\n",
    "# Check if dataset is not None before using tail\n",
    "display(dataset.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822cce3",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2bd0d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', 'U', '-'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['predict'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72966429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict\n",
       "N    96.811663\n",
       "U     1.848998\n",
       "Y     1.315634\n",
       "-     0.023705\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['predict'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae01df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8435, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', 'U'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove the Unknown Data\n",
    "dataset = dataset[~(dataset.predict=='-')]\n",
    "print(dataset.shape)\n",
    "dataset['predict'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bcde5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-', 'N', 'Y', 'U'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['consensus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4b5aeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "consensus\n",
       "-    94.534677\n",
       "N     4.149378\n",
       "Y     1.126260\n",
       "U     0.189686\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['consensus'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a555d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8427"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.chief_complaint.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0291c48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chief_complaint</th>\n",
       "      <th>predict</th>\n",
       "      <th>consensus</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chief_complaint, predict, consensus, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.chief_complaint.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e51f9ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict\n",
       "N    8168\n",
       "U     156\n",
       "Y     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['predict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a911a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01849436870183758"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "156/(8168+156+111)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ccb94ba",
   "metadata": {},
   "source": [
    "dataset['predict'] = dataset['predict'].apply(lambda x: 1 if x == 'Y' else (0 if x == 'N' else None))\n",
    "dataset['predict'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9db4050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8435, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f65ebf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', 'U'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['predict'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66944d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df = dataset.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e66113",
   "metadata": {},
   "source": [
    "## Create Entities"
   ]
  },
  {
   "cell_type": "raw",
   "id": "885b9176",
   "metadata": {},
   "source": [
    "def get_entities(text):\n",
    "    try:\n",
    "        # Process the text with spaCy\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Extract entities and their types\n",
    "        entities = {}\n",
    "        entity_list = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        for ent_text, ent_label in entity_list:\n",
    "            if ent_label in entities:\n",
    "                entities[ent_label].append(ent_text)\n",
    "            else:\n",
    "                entities[ent_label] = [ent_text]\n",
    "\n",
    "        return pd.Series({'entities': entities, 'entity': entity_list})\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        return pd.Series({'entities': None, 'entity': None})\n",
    "\n",
    "# Apply the function and create two columns in the DataFrame\n",
    "entity_df[['entities', 'entity']] = entity_df['chief_complaint'].apply(get_entities)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(entity_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2960b",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb26854f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chief_complaint</th>\n",
       "      <th>predict</th>\n",
       "      <th>consensus</th>\n",
       "      <th>year</th>\n",
       "      <th>entities</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"been feeling bad\" last 2 weeks &amp; switched BP ...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>2019</td>\n",
       "      <td>{'DATE': ['last 2 weeks', 'last week &amp;'], 'ORG...</td>\n",
       "      <td>[(last 2 weeks, DATE), (BP, ORG), (last week &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"can't walk\", reports onset at &lt;&lt;TIME&gt;&gt;. orien...</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>2019</td>\n",
       "      <td>{'DATE': ['last week'], 'ORG': ['UTI', 'CVA']}</td>\n",
       "      <td>[(last week, DATE), (UTI, ORG), (CVA, ORG)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"dehydration\" Chest hurts, hips hurt, cramps P...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019</td>\n",
       "      <td>{'DATE': ['today']}</td>\n",
       "      <td>[(today, DATE)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"gout flare up\" L arm swelling x 1 week. denie...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019</td>\n",
       "      <td>{'DATE': ['1 week']}</td>\n",
       "      <td>[(1 week, DATE)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"heart racing,\"dyspnea, and orthopnea that has...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>2019</td>\n",
       "      <td>{'DATE': ['the last 3 days'], 'CARDINAL': ['12...</td>\n",
       "      <td>[(the last 3 days, DATE), (122, CARDINAL), (PT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     chief_complaint predict consensus  year  \\\n",
       "0  \"been feeling bad\" last 2 weeks & switched BP ...       N         -  2019   \n",
       "1  \"can't walk\", reports onset at <<TIME>>. orien...       Y         N  2019   \n",
       "2  \"dehydration\" Chest hurts, hips hurt, cramps P...       Y         Y  2019   \n",
       "3  \"gout flare up\" L arm swelling x 1 week. denie...       Y         Y  2019   \n",
       "4  \"heart racing,\"dyspnea, and orthopnea that has...       N         -  2019   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'DATE': ['last 2 weeks', 'last week &'], 'ORG...   \n",
       "1     {'DATE': ['last week'], 'ORG': ['UTI', 'CVA']}   \n",
       "2                                {'DATE': ['today']}   \n",
       "3                               {'DATE': ['1 week']}   \n",
       "4  {'DATE': ['the last 3 days'], 'CARDINAL': ['12...   \n",
       "\n",
       "                                              entity  \n",
       "0  [(last 2 weeks, DATE), (BP, ORG), (last week &...  \n",
       "1        [(last week, DATE), (UTI, ORG), (CVA, ORG)]  \n",
       "2                                    [(today, DATE)]  \n",
       "3                                   [(1 week, DATE)]  \n",
       "4  [(the last 3 days, DATE), (122, CARDINAL), (PT...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d782687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming entity_df is your DataFrame\n",
    "# If needed, replace 'chief_complaint' with the column name containing the text data\n",
    "X = entity_df['chief_complaint']\n",
    "y = entity_df['predict']\n",
    "\n",
    "# Feature engineering - TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_vectorized = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09b904",
   "metadata": {},
   "source": [
    "## Basic RandomForrest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ae0d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.9676941315945465\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.97      1.00      0.98      3266\n",
      "           U       0.00      0.00      0.00        64\n",
      "           Y       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.97      3374\n",
      "   macro avg       0.32      0.33      0.33      3374\n",
      "weighted avg       0.94      0.97      0.95      3374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Class weights based on your class distribution\n",
    "class_weights = {'N': 1, 'U': len(y_train[y_train=='N']) / len(y_train[y_train=='U']), 'Y': len(y_train[y_train=='N']) / len(y_train[y_train=='Y'])}\n",
    "\n",
    "# Choose a model (Random Forest Classifier in this example) with class_weight parameter\n",
    "model = RandomForestClassifier(random_state=42, class_weight=class_weights)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display results for the test set\n",
    "print(\"Test Set Accuracy:\", accuracy)\n",
    "print(\"Test Set Classification Report:\\n\", classification_report_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a7e0081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict\n",
       "N    3266\n",
       "U      64\n",
       "Y      44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b2a3f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    3373\n",
       "Y       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predict = model.predict(X_test)\n",
    "validation_predict.tolist()\n",
    "pd.Series(validation_predict.tolist()).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d433c",
   "metadata": {},
   "source": [
    "# SMOTE Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ceb85f",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1175c88e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.97      1.00      0.98      3266\n",
      "           U       0.50      0.03      0.06        64\n",
      "           Y       0.86      0.14      0.24        44\n",
      "\n",
      "    accuracy                           0.97      3374\n",
      "   macro avg       0.78      0.39      0.43      3374\n",
      "weighted avg       0.96      0.97      0.96      3374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to oversample the minority classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced', None],  # Add 'balanced' for automatic class weights\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring='f1_macro', cv=5)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "# Train the final model with the best parameters on the resampled data\n",
    "final_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "final_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "classification_report_result_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Display results for the test set\n",
    "print(\"Test Set Classification Report:\\n\", classification_report_result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfa151",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f525a0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:17:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:17:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:17:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:17:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:17:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:17:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:18:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:18:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:18:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:18:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:18:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:19:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:19:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:19:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:19:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:20:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:20:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:20:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:20:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:20:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:20:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:21:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:21:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:21:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:21:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:22:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:22:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:23:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:23:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:24:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:25:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:25:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:25:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:25:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:25:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:26:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:26:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:27:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:27:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:28:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:28:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:29:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:30:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:31:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:32:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:33:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:34:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:34:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:34:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:34:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:34:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:34:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:35:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:35:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:35:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:35:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:35:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:35:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:35:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:36:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:36:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:36:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:36:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:37:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:37:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:37:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:38:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:38:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:38:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:39:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:39:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:39:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:39:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:39:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:40:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:40:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:40:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:41:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:41:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:42:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:42:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:43:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:43:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:43:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:44:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:45:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:46:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:46:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:46:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:46:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:46:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:46:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:46:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:47:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:47:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:47:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:48:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:48:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:48:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:48:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:48:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:48:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:49:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:49:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:49:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:49:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:50:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:50:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:50:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:50:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:51:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [05:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m y_pred_test_xgb \u001b[38;5;241m=\u001b[39m final_model_xgb\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluate the final XGBoost model on the test set\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m classification_report_result_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_test_xgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Display results for the test set\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost Test Set Classification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report_result_xgb)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2313\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2310\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   2312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2313\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2314\u001b[0m     labels_given \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/multiclass.py:117\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMix of label input types (string and number)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "# Assuming y_train and y_test are your target variables\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train_encoded)\n",
    "\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    objective='multi:softmax',  # Specify the objective for multi-class classification\n",
    "    num_class=len(label_encoder.classes_),  # Number of classes\n",
    "    # class_weight can be used for balancing classes\n",
    "    # You may adjust the weights based on the class distribution\n",
    "    class_weight={'N': 1, 'U': len(y_train[y_train=='N']) / len(y_train[y_train=='U']),\n",
    "                  'Y': len(y_train[y_train=='N']) / len(y_train[y_train=='Y'])},\n",
    ")\n",
    "\n",
    "\n",
    "# Define hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='f1_macro', cv=5)\n",
    "grid_search_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(best_params_xgb)\n",
    "\n",
    "# Train the final XGBoost model with the best parameters on the resampled data\n",
    "final_model_xgb = xgb.XGBClassifier(random_state=42, **best_params_xgb)\n",
    "final_model_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test_xgb = final_model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the final XGBoost model on the test set\n",
    "classification_report_result_xgb = classification_report(y_test, y_pred_test_xgb)\n",
    "# Display results for the test set\n",
    "print(\"XGBoost Test Set Classification Report:\\n\", classification_report_result_xgb)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test_xgb)\n",
    "print(cm)\n",
    "print((time.time() -t1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc70de5",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b5392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming entity_df is your DataFrame\n",
    "# If needed, replace 'chief_complaint' with the column name containing the text data\n",
    "X = entity_df['chief_complaint']\n",
    "y = entity_df['predict']\n",
    "\n",
    "# Feature engineering - TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_vectorized = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a5d7376",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\sourodeep.das\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming y_train and y_test are your target variables\u001b[39;00m\n\u001b[0;32m      5\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\sourodeep.das\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming y_train and y_test are your target variables\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train_encoded)\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Define hyperparameters to search over\n",
    "param_grid = {\n",
    "    'C': [1],\n",
    "    'kernel': ['rbf'],\n",
    "}\n",
    "\n",
    "# # Define hyperparameters to search over\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1,  5,  10],\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "# }\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grid_search_svm = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, scoring='f1_macro', cv=5)\n",
    "grid_search_svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "\n",
    "# Train the final SVM model with the best parameters on the resampled data\n",
    "final_model_svm = SVC(random_state=42, **best_params_svm)\n",
    "final_model_svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test_svm = final_model_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the final SVM model on the test set\n",
    "classification_report_result_svm = classification_report(y_test_encoded, y_pred_test_svm)\n",
    "\n",
    "\n",
    "\n",
    "# Display results for the test set\n",
    "print(\"SVM Test Set Classification Report:\\n\", classification_report_result_svm)\n",
    "# Visualize the confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_test_svm)\n",
    "print((time.time() -t1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0a570cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6de288eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'U', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "209d0f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Predicted Class: N\n",
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "# Suppose new_sentence is the new text you want to predict\n",
    "new_sentence = \"No gout but pain in knees\"\n",
    "\n",
    "# Transform the new sentence using the TfidfVectorizer from the pipeline\n",
    "new_sentence_vectorized = tfidf_vectorizer.transform([new_sentence])\n",
    "\n",
    "# Use the trained SVM model to predict the class of the new sentence\n",
    "predicted_class = final_model_svm.predict(new_sentence_vectorized)\n",
    "\n",
    "# Suppose label_encoder is the LabelEncoder instance used during training\n",
    "decoded_predicted_class = label_encoder.inverse_transform(predicted_class)\n",
    "\n",
    "# Display the decoded predicted class\n",
    "print(\"Decoded Predicted Class:\", decoded_predicted_class[0])\n",
    "\n",
    "\n",
    "# Display the predicted class\n",
    "print(\"Predicted Class:\", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a503a9",
   "metadata": {},
   "source": [
    "### SVC Model Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82ad1b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as svc_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import tarfile\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'svc_model.tar.gz'\n",
    "joblib.dump(final_model_svm, 'svc_model.joblib')  \n",
    "\n",
    "# Create a tar.gz file with the correct structure\n",
    "with tarfile.open(model_filename, 'w:gz') as tar:\n",
    "    tar.add('svc_model.joblib', arcname='svc_model.joblib') \n",
    "\n",
    "print(f'Model saved as {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24531e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Get the SageMaker execution role\n",
    "role = get_execution_role()\n",
    "\n",
    "# Specify the S3 location of your saved model artifacts (tar.gz file)\n",
    "model_location = 's3://factspan-data-products/GoutPrediction/model_data/svc_model.tar.gz'\n",
    "\n",
    "# Specify the local path to the inference script\n",
    "entry_point_local = 'inference.py'\n",
    "\n",
    "# Specify the local directory containing inference script\n",
    "source_dir_local = 'source_code'\n",
    "\n",
    "# Create an SKLearnModel for inference with IAM role and saved model artifacts\n",
    "svc_model = SKLearnModel(model_data=model_location,\n",
    "                         role=role,\n",
    "                         entry_point=entry_point_local,  # Your local inference script\n",
    "                         source_dir=source_dir_local,  # Local directory containing inference script\n",
    "                         framework_version='1.2-1')  # Version compatible with your trained model\n",
    "\n",
    "i+=1\n",
    "# Deploy the trained SVC model to an endpoint\n",
    "predictor = svc_model.deploy(instance_type='ml.m4.xlarge', \n",
    "                             endpoint_name=f'svc-prediction-endpoint-v{i}', \n",
    "                             initial_instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f319c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af1c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e26bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e0ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8e49b2",
   "metadata": {},
   "source": [
    "# Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "400ca92e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: N\n",
      "0.005481843153635661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Assuming entity_df is your DataFrame\n",
    "# If needed, replace 'chief_complaint' with the column name containing the text data\n",
    "X = entity_df['chief_complaint']\n",
    "y = entity_df['predict']\n",
    "\n",
    "# Feature engineering - TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_vectorized = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Assuming y_train is your target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Create a pipeline with TF-IDF, PredictAndDecode, and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "    ('predict_and_decode', PredictAndDecode(model=final_model_svm, label_encoder=label_encoder)),\n",
    "])\n",
    "\n",
    "# Train the pipeline on the data\n",
    "pipeline.fit(X, y_encoded)\n",
    "\n",
    "# Suppose new_sentence is the new text you want to predict\n",
    "new_sentence = \"possibility oft\"\n",
    "\n",
    "# Use the pipeline to predict and decode the class of the new sentence\n",
    "predicted_class = pipeline.transform([new_sentence])\n",
    "\n",
    "# Display the predicted class\n",
    "print(\"Predicted Class:\", predicted_class[0][0])\n",
    "print((time.time() -t1)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce6830",
   "metadata": {},
   "source": [
    "## Convert to Archive tar.gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea09ed51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gout_pipeline.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'gout_pipeline.tar.gz'\n",
    "joblib.dump(pipeline, 'gout_pipeline.joblib')  # Save the serialized model to 'model.joblib'\n",
    "\n",
    "filehandler = open(\"gout_pipeline.pkl\",\"wb\")\n",
    "pickle.dump(pipeline, filehandler)\n",
    "\n",
    "# Create a tar.gz file with the correct structure\n",
    "with tarfile.open(model_filename, 'w:gz') as tar:\n",
    "    tar.add('gout_pipeline.joblib', arcname='gout_pipeline.joblib')  # Include the model file with the correct name\n",
    "\n",
    "print(f'Model saved as {model_filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2d947",
   "metadata": {},
   "source": [
    "# Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "faedca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0802cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gout-prediction-v6\n",
      "------!"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Get the SageMaker execution role\n",
    "role = get_execution_role()\n",
    "\n",
    "# Specify the S3 location of your saved model artifacts (tar.gz file)\n",
    "model_location = 's3://factspan-data-products/models/gout_pipeline.tar.gz'\n",
    "\n",
    "# Specify the local path to the inference script\n",
    "entry_point_local = 'inference.py'\n",
    "\n",
    "# Specify the local directory containing inference script\n",
    "source_dir_local = 'source_code'\n",
    "\n",
    "# Create an SKLearnModel for inference with IAM role and saved model artifacts\n",
    "svc_model = SKLearnModel(model_data=model_location,\n",
    "                         role=role,\n",
    "                         entry_point=entry_point_local,  # Your local inference script\n",
    "                         source_dir=source_dir_local,  # Local directory containing inference script\n",
    "                         framework_version='1.2-1')  # Version compatible with your trained model\n",
    "\n",
    "i+=1\n",
    "endpoint_name = f'gout-prediction-v{i}'\n",
    "print(endpoint_name)\n",
    "# Deploy the trained SVC model to an endpoint\n",
    "predictor = svc_model.deploy(instance_type='ml.m4.xlarge', \n",
    "                             endpoint_name=endpoint_name, \n",
    "                             initial_instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ef0de674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gout-prediction-v6'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5cbfa4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Y\"'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = endpoint_name\n",
    "\n",
    "# Create a SageMaker client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name='ap-south-1')\n",
    "\n",
    "# Example plain text input, replace this with your actual input data\n",
    "plain_text_input = 'knee pain or gout'\n",
    "\n",
    "# Invoke the endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='text/plain',\n",
    "    Body=plain_text_input\n",
    ")\n",
    "\n",
    "# Read the response body as a string\n",
    "response_body_str = response['Body'].read().decode('utf-8')\n",
    "response_body_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b2d31a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Specify the endpoint URL\n",
    "endpoint_url = f\"https://runtime.sagemaker.ap-south-1.amazonaws.com/endpoints/{endpoint_name}/invocations\"\n",
    "\n",
    "# Example plain text input\n",
    "plain_text_input = 'Your text input goes here.'\n",
    "\n",
    "# Create a SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name='ap-south-1')\n",
    "\n",
    "# Invoke the endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,  # Provide the correct endpoint name\n",
    "    ContentType='text/plain',\n",
    "    Body=plain_text_input.encode('utf-8')\n",
    ")\n",
    "\n",
    "# Check the HTTP status code\n",
    "status_code = response['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "if status_code == 200:\n",
    "    try:\n",
    "        # Attempt to parse the response as JSON\n",
    "        result_json = response['Body'].read().decode('utf-8')\n",
    "        result_dict = json.loads(result_json)\n",
    "        print(result_dict)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "else:\n",
    "    print(f\"Endpoint returned non-200 status code: {status_code}\")\n",
    "    # Handle the error or return an appropriate response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d612d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
